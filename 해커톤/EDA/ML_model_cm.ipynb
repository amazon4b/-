{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b60a9cce-009b-4c16-b31b-adf6be11bef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.svm as svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#추가\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, fbeta_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8df1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, y_pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test,pred_proba)\n",
    "    \n",
    "# 아래 추가함 (pr_score, f2 score, gmean)\n",
    "# pr_score : 모델이 양성 클래스를 얼마나 정확하게 찾아내는지에 대한 정보를 제공(클래스 불균형이 존재할 때 유용)\n",
    "# fbeta_score : 정밀도(Precision)와 재현율(Recall)의 조화 평균을 계산하는 지표.재현율에 더 큰 가중치를 두는데, 이는 False Negatives를 최소화하는 데 중점\n",
    "# G-Mean : Sensitivity와 Specificity의 조화 평균. 클래스 간의 불균형을 고려하여 모델의 성능을 측정하며, 특히 Positive 클래스의 예측 성능이 중요한 경우에 유용\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    pr_score = average_precision_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "    # G-mean 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print('\\n정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1: {:.4f}'.format(F1))\n",
    "    print('AUC: {:.4f}'.format(AUC))\n",
    "    print('Fbeta :{:.4f}'.format(f2))\n",
    "    print('평균 정밀도 : {:.4f}'.format(pr_score))\n",
    "    print('gmean : {:.4f}'.format(gmean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d612f8d-efbc-4cfc-951d-640993de8efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>성별</th>\n",
       "      <th>수입 유형</th>\n",
       "      <th>최종 학력</th>\n",
       "      <th>결혼 여부</th>\n",
       "      <th>주거 형태</th>\n",
       "      <th>휴대전화 소유 여부</th>\n",
       "      <th>이메일 소유 여부</th>\n",
       "      <th>직업</th>\n",
       "      <th>산업군</th>\n",
       "      <th>...</th>\n",
       "      <th>rest_sec</th>\n",
       "      <th>rest_lab</th>\n",
       "      <th>cons_low</th>\n",
       "      <th>cons_drv</th>\n",
       "      <th>cons_sec</th>\n",
       "      <th>cons_lab</th>\n",
       "      <th>bus_low</th>\n",
       "      <th>bus_drv</th>\n",
       "      <th>bus_sec</th>\n",
       "      <th>bus_lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  성별  수입 유형  최종 학력  결혼 여부  주거 형태  휴대전화 소유 여부  이메일 소유 여부  직업  산업군  \\\n",
       "0       0   2      3      0      0      3           1          0   1    5   \n",
       "1       0   1      1      1      0      3           1          0   4   16   \n",
       "2       0   2      1      0      0      3           1          0   5   16   \n",
       "\n",
       "   ...  rest_sec  rest_lab  cons_low  cons_drv  cons_sec  cons_lab  bus_low  \\\n",
       "0  ...         0         0         0         0         0         0        0   \n",
       "1  ...         0         0         0         0         0         0        0   \n",
       "2  ...         0         0         0         0         0         0        0   \n",
       "\n",
       "   bus_drv  bus_sec  bus_lab  \n",
       "0        0        0        0  \n",
       "1        0        0        0  \n",
       "2        0        0        0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 작업요\n",
    "df = pd.read_csv('./final_datasets.csv', index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de6b33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59989 entries, 0 to 59999\n",
      "Data columns (total 29 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   TARGET      59989 non-null  int64\n",
      " 1   성별          59989 non-null  int64\n",
      " 2   수입 유형       59989 non-null  int64\n",
      " 3   최종 학력       59989 non-null  int64\n",
      " 4   결혼 여부       59989 non-null  int64\n",
      " 5   주거 형태       59989 non-null  int64\n",
      " 6   휴대전화 소유 여부  59989 non-null  int64\n",
      " 7   이메일 소유 여부   59989 non-null  int64\n",
      " 8   직업          59989 non-null  int64\n",
      " 9   산업군         59989 non-null  int64\n",
      " 10  가입연수        59989 non-null  int64\n",
      " 11  도시구분        59989 non-null  int64\n",
      " 12  월간 수입       59989 non-null  int64\n",
      " 13  home_shape  59989 non-null  int64\n",
      " 14  car_home    59989 non-null  int64\n",
      " 15  combinedFY  59989 non-null  int64\n",
      " 16  age_income  59989 non-null  int64\n",
      " 17  rest_low    59989 non-null  int64\n",
      " 18  rest_drv    59989 non-null  int64\n",
      " 19  rest_sec    59989 non-null  int64\n",
      " 20  rest_lab    59989 non-null  int64\n",
      " 21  cons_low    59989 non-null  int64\n",
      " 22  cons_drv    59989 non-null  int64\n",
      " 23  cons_sec    59989 non-null  int64\n",
      " 24  cons_lab    59989 non-null  int64\n",
      " 25  bus_low     59989 non-null  int64\n",
      " 26  bus_drv     59989 non-null  int64\n",
      " 27  bus_sec     59989 non-null  int64\n",
      " 28  bus_lab     59989 non-null  int64\n",
      "dtypes: int64(29)\n",
      "memory usage: 13.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d272648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TARGET', '성별', '수입 유형', '최종 학력', '결혼 여부', '주거 형태', '휴대전화 소유 여부',\n",
       "       '이메일 소유 여부', '직업', '산업군', '가입연수', '도시구분', '월간 수입', 'home_shape',\n",
       "       'car_home', 'combinedFY', 'age_income', 'rest_low', 'rest_drv',\n",
       "       'rest_sec', 'rest_lab', 'cons_low', 'cons_drv', 'cons_sec', 'cons_lab',\n",
       "       'bus_low', 'bus_drv', 'bus_sec', 'bus_lab'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3db3613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    53562\n",
       "1     6427\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50347006-7b94-4e16-9130-57c5b0f188bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature와 label 분리\n",
    "feature = df.drop('TARGET', axis=1)\n",
    "label = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80560943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "X_train_old, X_test, y_train_old , y_test = train_test_split(feature, label, test_size=0.3 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d9adf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    37465\n",
       "1     4527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_old.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c05b7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 언더샘플링 - 소수라벨과 다수라벨 비율 1:1\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "# X_train, y_train = undersample.fit_resample(X_train_old, y_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecd5ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오버샘플링 - 소수라벨과 다수라벨 비율 1:1 / 오버 샘플링이 좋음 투터님 피셜\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# X_train, y_train = oversample.fit_resample(X_train_old, y_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "196061cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote_sample = SMOTE(sampling_strategy='minority') \n",
    "X_train, y_train = smote_sample.fit_resample(X_train_old, y_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a4bd210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    37465\n",
       "1    37465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8389dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8087815294274655\n"
     ]
    }
   ],
   "source": [
    "# 1. Decision Tree를 이용한 학습\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=43)\n",
    "\n",
    "# 교차검증을 통한 과적합 or 과소적합 여부 확인\n",
    "cross_val = cross_val_score(dt , X_train , y=y_train ,cv=5, scoring='accuracy')\n",
    "print(np.mean(cross_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f12e6fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터: {'max_depth': 5, 'min_samples_split': 3}\n",
      "최고 예측 정확도: 0.6920\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV를 적용해 Decision Tree의 교차검증 및 하이퍼파라미터 튜닝\n",
    "\n",
    "parameters = {'max_depth' : [2, 3, 4, 5],\n",
    "             'min_samples_split' : [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_dt = GridSearchCV(dt, param_grid = parameters, cv=3, refit=True)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "dt = grid_dt.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_dt.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_dt.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f671599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[ 5766 10331]\n",
      " [  497  1403]]\n",
      "\n",
      "정확도: 0.3983\n",
      "정밀도: 0.1196\n",
      "재현율: 0.7384\n",
      "F1: 0.2058\n",
      "AUC: 0.5947\n",
      "Fbeta :0.3628\n",
      "평균 정밀도 : 0.1159\n",
      "gmean : 0.5143\n"
     ]
    }
   ],
   "source": [
    "# 임곗값 조정을 통한 recall값 향상\n",
    "dt.fit(X_train, y_train)\n",
    "pred = dt.predict(X_test)\n",
    "pred_proba = dt.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.3).fit(pred_proba)\n",
    "custom_pred = binarizer.transform(pred_proba)\n",
    "\n",
    "get_clf_eval(y_test, custom_pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71a0c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성별: 0.24272196100720686\n",
      "수입 유형: 0.17013157840718193\n",
      "최종 학력: 0.2949407838557785\n",
      "결혼 여부: 0.0\n",
      "주거 형태: 0.0\n",
      "휴대전화 소유 여부: 0.0\n",
      "이메일 소유 여부: 0.0\n",
      "직업: 0.01619430872433349\n",
      "산업군: 0.0116569553945742\n",
      "가입연수: 0.14296403678321312\n",
      "도시구분: 0.003269314206014566\n",
      "월간 수입: 0.022341456629613378\n",
      "home_shape: 0.0\n",
      "car_home: 0.09485340873747691\n",
      "combinedFY: 0.0\n",
      "age_income: 0.0009261962546071329\n",
      "rest_low: 0.0\n",
      "rest_drv: 0.0\n",
      "rest_sec: 0.0\n",
      "rest_lab: 0.0\n",
      "cons_low: 0.0\n",
      "cons_drv: 0.0\n",
      "cons_sec: 0.0\n",
      "cons_lab: 0.0\n",
      "bus_low: 0.0\n",
      "bus_drv: 0.0\n",
      "bus_sec: 0.0\n",
      "bus_lab: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 트리 기반 모델의 특성 중요도 확인\n",
    "for feature, importance in zip(X_train.columns, dt.feature_importances_):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "# 0에 가까울수록 중요도 낮고, 0.4나 0.5 정도가 중요도 높다할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10bcfaac-ce4a-4fb3-9d05-9b3289780eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536767649806485\n"
     ]
    }
   ],
   "source": [
    "# 2. RandomForest를 이용한 학습\n",
    "\n",
    "rf = RandomForestClassifier(random_state=43)\n",
    "\n",
    "cross_val = cross_val_score(rf , X_train , y=y_train ,cv=5, scoring='accuracy')\n",
    "print(np.mean(cross_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7650271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터: {'max_depth': 12, 'min_samples_split': 16}\n",
      "최고 예측 정확도: 0.7514\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 조정\n",
    "\n",
    "parameters = {\n",
    "    'max_depth' : [6, 8, 12],\n",
    "    'min_samples_split' : [16, 24]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid = parameters, cv=3, refit=True)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf = grid_rf.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_rf.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a388b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[6601 9496]\n",
      " [ 539 1361]]\n",
      "\n",
      "정확도: 0.4424\n",
      "정밀도: 0.1254\n",
      "재현율: 0.7163\n",
      "F1: 0.2134\n",
      "AUC: 0.6021\n",
      "Fbeta :0.3687\n",
      "평균 정밀도 : 0.1197\n",
      "gmean : 0.5420\n"
     ]
    }
   ],
   "source": [
    "# 임계값 조정 및 적용\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "pred_proba = rf.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.3).fit(pred_proba)\n",
    "custom_pred = binarizer.transform(pred_proba)\n",
    "\n",
    "get_clf_eval(y_test, custom_pred, pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "919ab130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성별: 0.14279402620345877\n",
      "수입 유형: 0.1158488864737136\n",
      "최종 학력: 0.14804480322607788\n",
      "결혼 여부: 0.024760643475298574\n",
      "주거 형태: 0.011061576522012595\n",
      "휴대전화 소유 여부: 7.613036939918717e-06\n",
      "이메일 소유 여부: 0.030631078131550176\n",
      "직업: 0.0473784111453448\n",
      "산업군: 0.04627585735635944\n",
      "가입연수: 0.09639170278189739\n",
      "도시구분: 0.04828054992150942\n",
      "월간 수입: 0.06862485545367127\n",
      "home_shape: 0.02471290030505721\n",
      "car_home: 0.067495007080093\n",
      "combinedFY: 0.038901556930923065\n",
      "age_income: 0.07761655086828147\n",
      "rest_low: 2.038793933120122e-05\n",
      "rest_drv: 0.00010881895000327317\n",
      "rest_sec: 0.00013819110199687342\n",
      "rest_lab: 7.049631246076451e-05\n",
      "cons_low: 5.763364865175482e-05\n",
      "cons_drv: 0.00047961259230085634\n",
      "cons_sec: 0.00015303487236673405\n",
      "cons_lab: 0.002615155031362884\n",
      "bus_low: 0.0005010300307779717\n",
      "bus_drv: 0.0022368914874273307\n",
      "bus_sec: 0.0016586880336297001\n",
      "bus_lab: 0.0031340410875021945\n"
     ]
    }
   ],
   "source": [
    "# 트리 기반 모델의 특성 중요도 확인\n",
    "for feature, importance in zip(X_train.columns, rf.feature_importances_):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b59b4ee-bf98-4694-ba36-9ea192f604d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6951421326571466\n"
     ]
    }
   ],
   "source": [
    "# 3. Logistic regrssion 을 이용한 학습\n",
    "\n",
    "lr = LogisticRegression(random_state=43)\n",
    "\n",
    "cross_val = cross_val_score(lr, X_train , y=y_train ,cv=5, scoring='accuracy')\n",
    "print(np.mean(cross_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf11d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터: {'C': 0.1, 'penalty': 'l2'}\n",
      "최고 예측 정확도: 0.6952\n"
     ]
    }
   ],
   "source": [
    "parameters = {'penalty': ['l2','l1'],\n",
    "          'C':[0.01,0.1,1,10]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, param_grid = parameters, cv=3, refit=True)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "lr = grid_lr.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_lr.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd33130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[ 5844 10253]\n",
      " [  456  1444]]\n",
      "\n",
      "정확도: 0.4050\n",
      "정밀도: 0.1235\n",
      "재현율: 0.7600\n",
      "F1: 0.2124\n",
      "AUC: 0.5974\n",
      "Fbeta :0.3742\n",
      "평균 정밀도 : 0.1192\n",
      "gmean : 0.5253\n"
     ]
    }
   ],
   "source": [
    "# 임계값 조정 및 모델 적용\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "pred_proba = lr.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.3).fit(pred_proba)\n",
    "custom_pred = binarizer.transform(pred_proba)\n",
    "\n",
    "get_clf_eval(y_test , custom_pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37b8f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성별: -1.1230039762410964\n",
      "수입 유형: -0.3124384738652864\n",
      "최종 학력: -0.8580271129115739\n",
      "결혼 여부: -0.07549284057591987\n",
      "주거 형태: -0.17914056009943521\n",
      "휴대전화 소유 여부: 2.0751142638569893\n",
      "이메일 소유 여부: -1.5640571565614863\n",
      "직업: -0.01296568604153789\n",
      "산업군: -0.00711091794886099\n",
      "가입연수: -0.5255404080839778\n",
      "도시구분: -0.16030142157888905\n",
      "월간 수입: -0.2672288802651252\n",
      "home_shape: 0.13741566013391826\n",
      "car_home: -0.42160702582152837\n",
      "combinedFY: -0.03602249749420847\n",
      "age_income: -0.03551457503870453\n",
      "rest_low: -0.006121401362827918\n",
      "rest_drv: -0.03001272767736507\n",
      "rest_sec: -0.010601800572843854\n",
      "rest_lab: -0.006682694356310621\n",
      "cons_low: 0.010480506431156472\n",
      "cons_drv: -0.0938149994803944\n",
      "cons_sec: -0.017066562293013794\n",
      "cons_lab: -0.020769554311190926\n",
      "bus_low: -0.046256157695187046\n",
      "bus_drv: -0.07198577419320697\n",
      "bus_sec: -0.3269413828893412\n",
      "bus_lab: -0.26743480025052535\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델의 특성 중요도 확인\n",
    "feature_importance = lr.coef_[0]  # 특성의 가중치 또는 중요도\n",
    "\n",
    "# 특성별 중요도 출력\n",
    "for feature, importance in zip(X_train.columns, feature_importance):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "# 가중치의 절댓값이 클수록 중요도 높음\n",
    "# 0에 가까울수록 중요도 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c19bdf49-9fb7-4784-9948-0759dcc798d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7944214600293608\n"
     ]
    }
   ],
   "source": [
    "# 4. KNN 을 이용한 학습\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "# knn에는 무작위성 추출(random_state)를 하지 않음.\n",
    "\n",
    "cross_val = cross_val_score(knn , X_train , y=y_train ,cv=5, scoring='accuracy')\n",
    "print(np.mean(cross_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2fb9101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하이퍼파라미터 조정\n",
    "\n",
    "# parameters = {'n_neighbors': [3, 5, 7, 9],\n",
    "#               'weights': ['uniform', 'distance']\n",
    "#           }\n",
    "\n",
    "# grid_knn = GridSearchCV(knn, param_grid = parameters, cv=3, refit=True)\n",
    "# grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# knn = grid_knn.best_estimator_\n",
    "\n",
    "# print(f\"최적 하이퍼 파라미터: {grid_knn.best_params_}\")\n",
    "# print(f\"최고 예측 정확도: {grid_knn.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e866262f-903f-4be9-a799-b9272849966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 임계값 조정 및 모델 적용\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "# pred = knn.predict(X_test)\n",
    "# pred_proba = knn.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "# binarizer = Binarizer(threshold=0.5).fit(pred_proba)\n",
    "# custom_pred = binarizer.transform(pred_proba)\n",
    "\n",
    "# get_clf_eval(y_test , custom_pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc599efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 29972, number of negative: 29972\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 59944, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 29972, number of negative: 29972\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 59944, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 29972, number of negative: 29972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145\n",
      "[LightGBM] [Info] Number of data points in the train set: 59944, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 29972, number of negative: 29972\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 59944, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 29972, number of negative: 29972\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 59944, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "0.7672761243827572\n"
     ]
    }
   ],
   "source": [
    "# 5. Lightgbm을 이용한 학습\n",
    "\n",
    "lgbm= LGBMClassifier(random_state=43)\n",
    "\n",
    "cross_val = cross_val_score(lgbm, X_train , y=y_train ,cv=5, scoring='accuracy')\n",
    "print(np.mean(cross_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cfaddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18733, number of negative: 18732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18732, number of negative: 18733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499987 -> initscore=-0.000053\n",
      "[LightGBM] [Info] Start training from score -0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18733, number of negative: 18732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18732, number of negative: 18733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499987 -> initscore=-0.000053\n",
      "[LightGBM] [Info] Start training from score -0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18733, number of negative: 18732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18732, number of negative: 18733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499987 -> initscore=-0.000053\n",
      "[LightGBM] [Info] Start training from score -0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18733, number of negative: 18732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 18732, number of negative: 18733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 37465, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499987 -> initscore=-0.000053\n",
      "[LightGBM] [Info] Start training from score -0.000053\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 37465, number of negative: 37465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 145\n",
      "[LightGBM] [Info] Number of data points in the train set: 74930, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "최적 하이퍼 파라미터: {'learning_rate': 0.1, 'n_neighbors': 100}\n",
      "최고 예측 정확도: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 조정\n",
    "\n",
    "parameters = {'n_neighbors': [100, 500],\n",
    "              'learning_rate': [0.05, 0.1]\n",
    "          }\n",
    "\n",
    "grid_lgbm = GridSearchCV(lgbm, param_grid = parameters, cv=2, verbose=1, refit=True)\n",
    "grid_lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm = grid_lgbm.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_lgbm.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_lgbm.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bf9ea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Info] Number of positive: 37465, number of negative: 37465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 145\n",
      "[LightGBM] [Info] Number of data points in the train set: 74930, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "[LightGBM] [Warning] Unknown parameter: n_neighbors\n",
      "오차행렬:\n",
      " [[8306 7791]\n",
      " [ 757 1143]]\n",
      "\n",
      "정확도: 0.5250\n",
      "정밀도: 0.1279\n",
      "재현율: 0.6016\n",
      "F1: 0.2110\n",
      "AUC: 0.5902\n",
      "Fbeta :0.3457\n",
      "평균 정밀도 : 0.1190\n",
      "gmean : 0.5571\n"
     ]
    }
   ],
   "source": [
    "# 임계값 조정 및 모델 적용\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "pred = lgbm.predict(X_test)\n",
    "pred_proba = lgbm.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.3).fit(pred_proba)\n",
    "custom_pred = binarizer.transform(pred_proba)\n",
    "\n",
    "get_clf_eval(y_test , custom_pred, pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3936f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7940611237154678\n"
     ]
    }
   ],
   "source": [
    "# 6. XGboost \n",
    "xgb = XGBClassifier(random_state=43)\n",
    "\n",
    "cross_val = cross_val_score(xgb, X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "print(np.mean(cross_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7eb90e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "최적 하이퍼 파라미터: {'learning_rat': 0.01, 'n_estimators': 200}\n",
      "최고 예측 정확도: 0.8099\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 조정\n",
    "parameters = {'learning_rat': [0.01, 0.1],  \n",
    "              'n_estimators': [50, 100, 200]\n",
    "          }\n",
    "\n",
    "grid_xgb = GridSearchCV(xgb, param_grid=parameters, cv=5, verbose=1, refit=True)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb = grid_xgb.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_xgb.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_xgb.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b32a3b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[10163  5934]\n",
      " [ 1012   888]]\n",
      "\n",
      "정확도: 0.6140\n",
      "정밀도: 0.1302\n",
      "재현율: 0.4674\n",
      "F1: 0.2036\n",
      "AUC: 0.5732\n",
      "Fbeta :0.3079\n",
      "평균 정밀도 : 0.1171\n",
      "gmean : 0.5432\n"
     ]
    }
   ],
   "source": [
    "# 임계값 조정 및 모델 적용\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "pred = xgb.predict(X_test)\n",
    "pred_proba = xgb.predict_proba(X_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=0.3).fit(pred_proba)\n",
    "custom_pred = binarizer.transform(pred_proba)\n",
    "\n",
    "get_clf_eval(y_test , custom_pred, pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
