{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.svm as svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../EDA/scaled_data.csv')\n",
    "train_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어느 산업군에서 어느 직업이 연체 여부가 높은지 확인\n",
    "\n",
    "# 직업 수, 산업군 수의 편중을 완화하기 위하여 각 직업 별 연체 여부로 연체율 확인/ 각 산업군 별 연체 여부로 연체율 확인\n",
    "# 위에서 확인한 각 산업군의 연체율을 총 평균연체율(10.71%)보다 높은 산업군 15개(총 33개의 직업 중)\n",
    "# 각 산업군의 연체율을 총 평균연체율(10.71%)보다 높은 직업 8개(총 19개의 직업 중)\n",
    "\n",
    "## 종사하는 산업군의 전체 인원수를 확인하여 너무 적은 경우 제외\n",
    "## 직업에 종사하는 인원수를 확인하여 너무 적은 경우 제외\n",
    "\n",
    "# 위의 사항 고려하여 top3 산업군과 top4 직업 선정\n",
    "# 이를 결합하여 1위 산업군- 1위 직업, 2위 직업, 3위 직업 ... 3위 산업군- 1위 직업, 2위 직업, 3위 직업 비교\n",
    "# 어느 파생변수가 가장 유의한지 -> 그 산업군에서 그 직업이 연체율이 높다고 예측 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업군 Top3 : 8(레스토랑-0.195%), 0(건설업-0.155%), 24(자영업-0.137%)\n",
    "# 직업 Top4 : 15(저임금 노동자-0.237%), 12(운전자-0.150%), 17(보안업계종사자-0.149%), 5(단순노동자-0.140%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업군_직업 컬럼 생성 함수\n",
    "def create_job_column(df, ind_value, job_value):\n",
    "\n",
    "#    새로운 컬럼을 생성하고 특정 조건에 따라 값을 할당하는 함수\n",
    "\n",
    "#    Parameters:\n",
    "#    - df: 데이터프레임\n",
    "#    - job_value: 직업 구분코드\n",
    "#    - ind_value : 산업군 구분코드\n",
    "\n",
    "#    Returns:\n",
    "#    - df: 새로운 컬럼을 추가한 데이터프레임\n",
    "    \n",
    "  new_column_name = f\"{ind_value}_{job_value}\"\n",
    "  # 조건에 맞는 행에 1을 할당하여 새로운 컬럼에 추가\n",
    "  df[new_column_name] = (df['산업군'] == ind_value) & (df['직업'] == job_value)\n",
    "  # True/False를 1/0으로 변환\n",
    "  df[new_column_name] = df[new_column_name].astype(int)\n",
    "    \n",
    "  return df\n",
    "# 함수 사용 예시\n",
    "# create_job_column(your_df, ind_value, job_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업군 8_직업 컬럼 생성\n",
    "create_job_column(train_copy, 8, 15)\n",
    "create_job_column(train_copy, 8, 12)\n",
    "create_job_column(train_copy, 8, 17)\n",
    "create_job_column(train_copy, 8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업군 0_직업 컬럼 생성\n",
    "create_job_column(train_copy, 0, 15)\n",
    "create_job_column(train_copy, 0, 12)\n",
    "create_job_column(train_copy, 0, 17)\n",
    "create_job_column(train_copy, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업군 24_직업 컬럼 생성\n",
    "create_job_column(train_copy, 24, 15)\n",
    "create_job_column(train_copy, 24, 12)\n",
    "create_job_column(train_copy, 24, 17)\n",
    "create_job_column(train_copy, 24, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 '가족크기범주' 생성\n",
    "train_copy['가족크기범주'] = pd.cut(train_copy['가족 구성원 수'], bins=[0, 2, 4,float('inf')],  \n",
    "                    labels=['0','1', '2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터타입 category -> int 변경 \n",
    "train_copy['가족크기범주'] = train_copy['가족크기범주'].dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 'combinedFY' 생성\n",
    "# 조건 설정\n",
    "conditions = [\n",
    "(train_copy['가족크기범주'] == 0) & (train_copy['가입연수'] == 0),\n",
    "(train_copy['가족크기범주'] == 0) & (train_copy['가입연수'] == 1),\n",
    "(train_copy['가족크기범주'] == 0) & (train_copy['가입연수'] == 2),\n",
    "(train_copy['가족크기범주'] == 0) & (train_copy['가입연수'] == 3),\n",
    "\n",
    "(train_copy['가족크기범주'] == 1) & (train_copy['가입연수'] == 0),\n",
    "(train_copy['가족크기범주'] == 1) & (train_copy['가입연수'] == 1),\n",
    "(train_copy['가족크기범주'] == 1) & (train_copy['가입연수'] == 2),\n",
    "(train_copy['가족크기범주'] == 1) & (train_copy['가입연수'] == 3),\n",
    "\n",
    "\n",
    "(train_copy['가족크기범주'] == 2) & (train_copy['가입연수'] == 0),\n",
    "(train_copy['가족크기범주'] == 2) & (train_copy['가입연수'] == 1),\n",
    "(train_copy['가족크기범주'] == 2) & (train_copy['가입연수'] == 2),\n",
    "(train_copy['가족크기범주'] == 2) & (train_copy['가입연수'] == 3),\n",
    "]\n",
    "# 할당할 값 설정\n",
    "values = [0, 1, 2, 3, 4, 5, 6, 7, 8,9,10,11]\n",
    "\n",
    "# np.select를 사용하여 조건에 맞는 값을 'y' 컬럼에 할당\n",
    "train_copy['combinedfY'] = np.select(conditions, values, default=0)\n",
    "#train_copy = train_copy.drop(['차량 소유 여부', '부동산 소유 여부', '주거 형태', '근속연수'], axis=1)\n",
    "train_copy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 'age_income' 생성\n",
    "# 임금수준 & 나이활용한 파생변수\n",
    "conditions1 = [\n",
    "(train_copy['나이'] == 0) & (train_copy['월간 수입'] == 0),\n",
    "(train_copy['나이'] == 0) & (train_copy['월간 수입'] == 1),\n",
    "(train_copy['나이'] == 0) & (train_copy['월간 수입'] == 2),\n",
    "(train_copy['나이'] == 0) & (train_copy['월간 수입'] == 3),\n",
    "\n",
    "(train_copy['나이'] == 1) & (train_copy['월간 수입'] == 0),\n",
    "(train_copy['나이'] == 1) & (train_copy['월간 수입'] == 1),\n",
    "(train_copy['나이'] == 1) & (train_copy['월간 수입'] == 2),\n",
    "(train_copy['나이'] == 1) & (train_copy['월간 수입'] == 3),\n",
    "\n",
    "(train_copy['나이'] == 2) & (train_copy['월간 수입'] == 0),\n",
    "(train_copy['나이'] == 2) & (train_copy['월간 수입'] == 1),\n",
    "(train_copy['나이'] == 2) & (train_copy['월간 수입'] == 2),\n",
    "(train_copy['나이'] == 2) & (train_copy['월간 수입'] == 3),\n",
    "\n",
    "(train_copy['나이'] == 3) & (train_copy['월간 수입'] == 0),\n",
    "(train_copy['나이'] == 3) & (train_copy['월간 수입'] == 1),\n",
    "(train_copy['나이'] == 3) & (train_copy['월간 수입'] == 2),\n",
    "(train_copy['나이'] == 3) & (train_copy['월간 수입'] == 3),\n",
    "\n",
    "(train_copy['나이'] == 4) & (train_copy['월간 수입'] == 0),\n",
    "(train_copy['나이'] == 4) & (train_copy['월간 수입'] == 1),\n",
    "(train_copy['나이'] == 4) & (train_copy['월간 수입'] == 2),\n",
    "(train_copy['나이'] == 4) & (train_copy['월간 수입'] == 3),\n",
    "\n",
    "]\n",
    "# 할당할 값 설정\n",
    "values = [0,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "# np.select를 사용하여 조건에 맞는 값을 'y' 컬럼에 할당\n",
    "train_copy['age_income'] = np.select(conditions1, values, default=0)\n",
    "train_copy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카이제곱 검정은 파생변수가 범주형일 때 유의미한지 검증하는 대표적인 지표.\n",
    "# 결과로 나온 출력에서 p-value가 0.05 미만이면서 chi2가 가장 높은 파생변수가\n",
    "# 카이제곱 검정으로 봤을때 가장 의미가 있는 피쳐.\n",
    "\n",
    "# 일단 가설을 설정했다면 그 가설에 필요한 변수만 빼서 카이제곱 검정을 돌려. \n",
    "# 그래서 0.05이상 나오면 그 가설과 파생변수는 유의미하니 사용 가능.\n",
    "# 그리고 이것도 통계적 요소 대립가설을 언급하며 논리를 펼칠 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value값 확인\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2_results = {}\n",
    "categorical_features = ['24_15', '24_12', '24_17', '24_5']\n",
    "\n",
    "# 나의 가설은 이렇다.\n",
    "# 비교적 나이가 젊은 층 중 기혼자가 미혼자에 비해 재정 관리 능력이 더 뛰어날 것.\n",
    "# 특히 월간 수입이 이러한 범위에 있는 사람은 연체 확률이 더 높거나 낮을 것.\n",
    "# 그럼 내 가설에 필요한 피처들을 카이제곱 검정에 넣어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value값 확인\n",
    "for feature in categorical_features:\n",
    "    contingency_table = pd.crosstab(train_copy[feature], train_copy['TARGET'])\n",
    "    \n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    chi2_results[feature] = {'chi2': chi2, 'p-value': p}\n",
    "\n",
    "\n",
    "chi2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature와 label 분리\n",
    "feature = train_copy.drop('TARGET', axis=1)\n",
    "label = train_copy['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "X_train_old, X_test, y_train_old , y_test = train_test_split(feature, label, test_size=0.3 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_old.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_train, y_train = SMOTE(random_state = 22).fit_resample(X_train_old, y_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decision Tree를 이용한 학습\n",
    "# 1-1. GridSearchCV를 적용해 Decision Tree의 교차검증 및 하이퍼파라미터 튜닝\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth' : [2, 3, 4, 5],\n",
    "             'min_samples_split' : [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_dt = GridSearchCV(dt, param_grid = parameters, cv=3, refit=True)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "dt = grid_dt.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_dt.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_dt.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델로부터 예측 확률 계산\n",
    "# predicted_probabilities = dt.predict_proba(X_test)\n",
    "\n",
    "# 임계값 설정\n",
    "# threshold = 0.6  # 임계값 설정 (예시로 0.6으로 설정)\n",
    "\n",
    "# 예측값 변환\n",
    "# predicted_classes = (predicted_probabilities[:, 1] >= threshold).astype(int)  # 양성 클래스의 확률에 대해 임계값 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 재설정\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = 0.5\n",
    "\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "custom_predict\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 적용\n",
    "pred = dt.predict(X_test)\n",
    "pred_proba = dt.predict_proba(X_test)\n",
    "pred_proba_1 = pred_proba[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test , pred)\n",
    "prec = precision_score(y_test , pred)\n",
    "rec = recall_score(y_test , pred)\n",
    "f1score = f1_score(y_test, pred)\n",
    "auc_score = roc_auc_score(y_test , pred_proba_1)\n",
    "print(f'의사결정나무 정확도 : {acc:.3f}')\n",
    "print(f'의사결정나무 정밀도 : {prec:.3f}')\n",
    "print(f'의사결정나무 재현율 : {rec:.3f}')\n",
    "print(f'의사결정나무 f1_score : {f1score:.3f}')\n",
    "print(f'의사결정나무 roc_auc : {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 기반 모델의 특성 중요도 확인\n",
    "for feature, importance in zip(X_train.columns, dt.feature_importances_):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. RandomForest를 이용한 학습\n",
    "# 2-1. GridSearchCV를 적용해 RandomForest의 교차검증 및 하이퍼파라미터 튜닝\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'max_depth' : [6, 8, 12],\n",
    "    'min_samples_split' : [16, 24]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid = parameters, cv=3, refit=True)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf = grid_rf.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_rf.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest 적용\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "pred_proba = rf.predict_proba(X_test)\n",
    "pred_proba_1 = pred_proba[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test , pred)\n",
    "prec = precision_score(y_test , pred)\n",
    "rec = recall_score(y_test , pred)\n",
    "f1score = f1_score(y_test, pred)\n",
    "auc_score = roc_auc_score(y_test , pred_proba_1)\n",
    "\n",
    "print(f'랜덤포레스트 정확도 : {acc:.3f}')\n",
    "print(f'랜덤포레스트 정밀도 : {prec:.3f}')\n",
    "print(f'랜덤포레스트 재현율 : {rec:.3f}')\n",
    "print(f'랜덤포레스트 f1_score : {f1score:.3f}')\n",
    "print(f'랜덤포레스트 roc_auc : {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 기반 모델의 특성 중요도 확인\n",
    "for feature, importance in zip(X_train.columns, rf.feature_importances_):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logistic regrssion 을 이용한 학습\n",
    "# 3-1. GridSearchCV를 적용해 Logistic regrssion의 교차검증 및 하이퍼파라미터 튜닝\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "parameters = {'penalty': ['l2','l1'],\n",
    "          'C':[0.01,0.1,1,10]}\n",
    "\n",
    "grid_lr = GridSearchCV(lr, param_grid = parameters, cv=3, refit=True)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "lr = grid_lr.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_lr.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-2. Logistic Regression 적용\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "pred_proba = lr.predict_proba(X_test)\n",
    "pred_proba_1 = pred_proba[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test , pred)\n",
    "prec = precision_score(y_test , pred)\n",
    "rec = recall_score(y_test , pred)\n",
    "auc_score = roc_auc_score(y_test , pred_proba_1)\n",
    "f1score = f1_score(y_test, pred)\n",
    "\n",
    "print(f'Logistic regrssion 정확도 : {acc:.3f}')\n",
    "print(f'Logistic regrssion 정밀도 : {prec:.3f}')\n",
    "print(f'Logistic regrssion 재현율 : {rec:.3f}')\n",
    "print(f'Logistic regrssion f1_score : {f1score:.3f}')\n",
    "print(f'Logistic regrssion roc_auc : {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델의 특성 중요도 확인\n",
    "feature_importance = lr.coef_[0]  # 특성의 가중치 또는 중요도\n",
    "\n",
    "# 특성별 중요도 출력\n",
    "for feature, importance in zip(X_train.columns, feature_importance):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. KNN 을 이용한 학습\n",
    "# 5-1. GridSearchCV를 적용해 KNN의 교차검증 및 하이퍼파라미터 튜닝\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [3, 5, 7, 9],\n",
    "              'weights': ['uniform', 'distance']\n",
    "          }\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_grid = parameters, cv=3, refit=True)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "knn = grid_knn.best_estimator_\n",
    "\n",
    "print(f\"최적 하이퍼 파라미터: {grid_knn.best_params_}\")\n",
    "print(f\"최고 예측 정확도: {grid_knn.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-2 knn 적용\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test) \n",
    "\n",
    "acc = accuracy_score(y_test , pred)\n",
    "prec = precision_score(y_test , pred)\n",
    "rec = recall_score(y_test , pred)\n",
    "auc_score = roc_auc_score(y_test , pred)\n",
    "f1score = f1_score(y_test, pred)\n",
    "\n",
    "print(f'KNN 정확도 : {acc:.3f}')\n",
    "print(f'KNN 정밀도 : {prec:.3f}')\n",
    "print(f'KNN 재현율 : {rec:.3f}')\n",
    "print(f'KNN f1_score : {f1score:.3f}')\n",
    "print(f'KNN roc_auc : {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. xgboost 를 이용한 학습\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators = 150,\n",
    "                            learning_rate = 0.2,\n",
    "                            max_depth = 10,\n",
    "                            min_child_weight = 5,\n",
    "                            gamma = 10)\n",
    "\n",
    "# fit\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "acc = accuracy_score(y_test , pred)\n",
    "prec = precision_score(y_test , pred)\n",
    "rec = recall_score(y_test , pred)\n",
    "auc_score = roc_auc_score(y_test , pred)\n",
    "f1score = f1_score(y_test, pred)\n",
    "\n",
    "\n",
    "# score print\n",
    "print(f'xgboost 정확도 : {acc:.3f}')\n",
    "print(f'xgboost 정밀도 : {prec:.3f}')\n",
    "print(f'xgboost 재현율 : {rec:.3f}')\n",
    "print(f'xgboost f1_score : {f1score:.3f}')\n",
    "print(f'xgboost roc_auc : {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Lightgbm을 이용한 학습\n",
    "# 5-1. GridSearchCV를 적용해 Lightgbm의 교차검증 및 하이퍼파라미터 튜닝\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm= LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False, force_row_wise=True)\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm.fit(X_train, y_train, eval_metric='logloss', eval_set=evals)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "pred = lgbm.predict(X_test)\n",
    "pred_proba = lgbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(y_test , pred)\n",
    "prec = precision_score(y_test, pred)\n",
    "rec = recall_score(y_test , pred)\n",
    "auc_score = roc_auc_score(y_test , pred)\n",
    "f1score = f1_score(y_test, pred)\n",
    "\n",
    "print(f'lightgbm 정확도 : {acc:.3f}')\n",
    "print(f'lightgbm 정밀도 : {prec:.3f}')\n",
    "print(f'lightgbm 재현율 : {rec:.3f}')\n",
    "print(f'lightgbm f1_score : {f1score:.3f}')\n",
    "print(f'lightgbm roc_auc : {auc_score:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
